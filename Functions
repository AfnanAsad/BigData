import java.util.regex.Pattern
def decimalStrip(inputValue: String, decimal_point: String): String = {
    if (inputValue == null) return null
    val filter = inputValue.replaceAll("[^0-9-\\" + decimal_point + "]", "")

    if (!(filter == "")) {
      val regx = "^(-)(0+)(.*)|^(0+)(.*)"
      val `match` = Pattern.compile(regx).matcher(filter)
      if (`match`.find) if (`match`.group(1) != null) return `match`.group(1) + `match`.group(3)
      else return `match`.group(5)
      return filter
    }
    "0"
  }


 def stringFilter(inputValue: String, searchString: String): String = {
    if (inputValue == null) return null
    val inputChars = inputValue.toCharArray
    val searchStringChars = searchString.toCharArray
    val returnset = new util.LinkedList[Character]
    var i = 0
    while (i < inputChars.length) {
      {
        var j = 0
        while (j < searchStringChars.length) {
          {
            if (inputChars(i) == searchStringChars(j)) {
              returnset.add(inputChars(i))
              break //todo: break is not supported
            }
          }
          {
            j += 1; j - 1
          }
        }
      }
      {
        i += 1; i - 1
      }
    }
    var returnString = ""
    import scala.collection.JavaConversions._
    for (c <- returnset) {
      returnString += c
    }
    returnString
  }


def stringLeftTrim(inputValue: String): String = {
    if (inputValue == null) return null
    inputValue.replaceFirst("\\s+", "")
  }

https://alvinalexander.com/scala/how-find-difference-intersection-distinct-characters-in-string

  val rdd:RDD[CassandraRow]=spark.sparkContext.parallelize(Seq(
      CassandraRow.fromMap(Map("puid"->"p1","vuid"->"v1","e1"->1,"e2"->null,"e3"->1,"edate"->"2015-01-02 00:00:00.000")),
      CassandraRow.fromMap(Map("puid"->"p1","vuid"->"v2","e1"->null,"e2"->1,"e3"->1,"edate"->"2016-01-02 00:00:00.000")),
      CassandraRow.fromMap(Map("puid"->"p1","vuid"->"v3","e1"->null,"e2"->null,"e3"->1,"edate"->"2017-01-02 00:00:00.000")),
      CassandraRow.fromMap(Map("puid"->"p2","vuid"->"v1","e1"->1,"e2"->null,"e3"->null,"edate"->"2017-08-02 00:00:00.000")),
      CassandraRow.fromMap(Map("puid"->"p2","vuid"->"v2","e1"->1,"e2"->1,"e3"->null,"edate"->"2017-01-06 00:00:00.000")),
      CassandraRow.fromMap(Map("puid"->"p3","vuid"->"v1","e1"->1,"e2"->null,"e3"->null,"edate"->"2017-01-06 00:00:00.000"))
    ))

  countElement(rdd,"e1","e2","e3")
  

  def countElement(rdd1:RDD[CassandraRow],elements:String*)
  {
    val countList=rdd1.filter({
      r=> elements.filter(element=> !r.isNullAt(element)).size>1
    }).map(r=>(r.getString("puid"),r.getDate("edate"))).collect()
  rdd1.filter(r=> countList.exists(x=>x._1.equalsIgnoreCase(r.getString("puid")) && (r.getDate("edate").after(x._2) ||r.getDate("edate").equals(x._2)))).foreach(println)
  }
